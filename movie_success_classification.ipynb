{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_before_df=pd.read_csv('./data/before_covid19.csv') # 10296 행\n",
    "covid_df=pd.read_csv('./data/covid19.csv') # 666 행 \n",
    "covid_after_df=pd.read_csv('./data/after_covid19.csv') # 529 행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test 분할을 위한 데이터 결합\n",
    "train_test_df = pd.concat([covid_before_df, covid_after_df], axis=0)\n",
    "train_test_df['success'] = train_test_df['ROI'].apply(lambda x: 1 if x >= 100 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df['ROI'] = covid_df.apply(lambda row: (row['profit'] / row['budget'])*100, axis=1)\n",
    "covid_df['success'] = covid_df['ROI'].apply(lambda x: 1 if x >= 100 else 0)\n",
    "covid_y_test=covid_df['success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_test_df.drop(['id','title','ROI','cast','director','adjusted_revenue','adjusted_budget','revenue','release_date','profit','popularity'],axis=1,inplace=True) \n",
    "covid_df.drop(['id','title','ROI','cast','director','adjusted_revenue','adjusted_budget','revenue','release_date','profit','popularity'],axis=1,inplace=True)\n",
    "\n",
    "# Train-Validation 분할 (8:2)\n",
    "X_train,X_test,y_train,y_test = train_test_split(train_test_df.drop('success',axis=1),train_test_df['success'],test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_one_hot_encoding(data, column_name):\n",
    "    # 문자열 분리\n",
    "    data[column_name] = data[column_name].str.split(', ')\n",
    "    \n",
    "    # 고유한 값 추출\n",
    "    all_categories = set([item for sublist in data[column_name] for item in sublist])\n",
    "    \n",
    "    # 원핫 인코딩 적용\n",
    "    for category in all_categories:\n",
    "        data[category] = data[column_name].apply(lambda x: 1 if category in x else 0)\n",
    "    \n",
    "    # 원핫 인코딩 대상 열 제거\n",
    "    data = data.drop(column_name, axis=1)\n",
    "    \n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=apply_one_hot_encoding(X_train,'genres')\n",
    "X_test=apply_one_hot_encoding(X_test,'genres')\n",
    "covid_df=apply_one_hot_encoding(covid_df,'genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[X_train.columns]\n",
    "covid_df = covid_df[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 평가 지표 계산 함수\n",
    "def evaluate(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# K-Fold 설정 (5개 폴드로 교차 검증)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2)\n",
    "\n",
    "# XGBoost 모델 기본 설정\n",
    "xgb_model = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    random_state=2\n",
    ")\n",
    "\n",
    "# 최적화할 하이퍼파라미터\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(500, 801, 100),\n",
    "    'max_depth': np.arange(3, 5),\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV 적용 (n_iter=60, 5-fold CV, f1-score 기준)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=60,  # 랜덤으로 60개 조합 탐색\n",
    "    scoring='f1',\n",
    "    cv=kf,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=2\n",
    ")\n",
    "\n",
    "# 학습 진행\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"최적의 하이퍼파라미터:\", random_search.best_params_)\n",
    "\n",
    "# 최적의 모델 추출\n",
    "best_xgb = random_search.best_estimator_\n",
    "\n",
    "# 학습 데이터 및 테스트 데이터 예측\n",
    "y_train_pred = best_xgb.predict(X_train)\n",
    "y_test_pred = best_xgb.predict(X_test)\n",
    "\n",
    "# 학습 데이터 평가\n",
    "train_accuracy, train_precision, train_recall, train_f1 = evaluate(y_train, y_train_pred)\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "test_accuracy, test_precision, test_recall, test_f1 = evaluate(y_test, y_test_pred)\n",
    "\n",
    "# 평가 결과를 데이터프레임으로 정리\n",
    "evaluation_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Train': [train_accuracy, train_precision, train_recall, train_f1],\n",
    "    'Test': [test_accuracy, test_precision, test_recall, test_f1]\n",
    "})\n",
    "\n",
    "# 평가 결과를 CSV 파일로 저장\n",
    "evaluation_df.to_csv('model_evaluation.csv', index=False)\n",
    "\n",
    "print(f\"학습 데이터 평가:\\n{evaluation_df[['Metric', 'Train']]}\")\n",
    "print(f\"테스트 데이터 평가:\\n{evaluation_df[['Metric', 'Test']]}\")\n",
    "print(\"\\n평가 결과가 'model_evaluation.csv' 파일로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 데이터프레임으로 변환\n",
    "df = pd.read_csv('model_evaluation.csv')\n",
    "\n",
    "# 학습 데이터와 테스트 데이터의 성능 차이 계산\n",
    "df['accuracy_diff'] = df['train_accuracy'] - df['test_accuracy']\n",
    "df['precision_diff'] = df['train_precision'] - df['test_precision']\n",
    "df['recall_diff'] = df['train_recall'] - df['test_recall']\n",
    "df['f1_diff'] = df['train_f1'] - df['test_f1']\n",
    "\n",
    "# 저장\n",
    "df[['params', 'accuracy_diff', 'precision_diff', 'recall_diff', 'f1_diff']].to_csv('diff.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "파일 확인 후"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "\n",
    "# XGBoost 모델 기본 설정\n",
    "xgb_model = XGBClassifier(\n",
    "    subsample=0.7, \n",
    "    n_estimators=700, \n",
    "    max_depth=3,\n",
    "    learning_rate=0.01,\n",
    "    colsample_bytree=0.8, \n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    random_state=2\n",
    ")\n",
    "\n",
    "\n",
    "# XGBoost 모델 학습\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# K-Fold 설정 (5개 폴드로 교차 검증)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2)\n",
    "\n",
    "# K-Fold 교차 검증 결과 얻기\n",
    "# 교차 검증 수행\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']  # 여러 지표를 평가\n",
    "cv_results = cross_validate(xgb_model, X_train, y_train, cv=kf, scoring=scoring)\n",
    "\n",
    "# 각 지표의 평균 결과 출력\n",
    "print(\"교차 검증 결과:\")\n",
    "print(\"정확도 평균:\", np.mean(cv_results['test_accuracy']))\n",
    "print(\"정밀도 평균:\", np.mean(cv_results['test_precision']))\n",
    "print(\"재현율 평균:\", np.mean(cv_results['test_recall']))\n",
    "print(\"F1 점수 평균:\", np.mean(cv_results['test_f1']))\n",
    "\n",
    "\n",
    "print(\"훈련데이터\")\n",
    "# 예측 및 평가 (훈련 데이터에 대한 예측)\n",
    "y_train_pred = xgb_model.predict(X_train)\n",
    "evaluate(y_train,y_train_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# 모델 정의\n",
    "rf_model = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    random_state=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500,600],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "}\n",
    "\n",
    "# KFold 정의 (5-fold 교차 검증)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2)\n",
    "\n",
    "# GridSearchCV로 파라미터 최적화\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=kf, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적 파라미터 출력\n",
    "print(\"최적 파라미터:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 성능평가\n",
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"테스트데이터\")\n",
    "# 예측 및 평가 (훈련 데이터에 대한 예측)\n",
    "y_test_pred = xgb_model.predict(X_test)\n",
    "evaluate(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = xgb_model.predict(X_train)\n",
    "evaluate(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코비드 예측\n",
    "y_pred=xgb_model.predict(covid_df)\n",
    "evaluate(covid_y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "def roc_curve_plot(y_test , pred_proba_c1):\n",
    "    # 임곗값에 따른 FPR, TPR 값을 반환 받음. \n",
    "    fprs , tprs , thresholds = roc_curve(y_test ,pred_proba_c1)\n",
    "\n",
    "    # AUC 값 계산\n",
    "    auc_score = roc_auc_score(y_test, pred_proba_c1)\n",
    "\n",
    "    # ROC Curve를 plot 곡선으로 그림\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.plot(fprs, tprs, label=f'ROC Curve (AUC = {auc_score:.3f})')\n",
    "    \n",
    "    # 가운데 대각선 직선을 그림\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    \n",
    "    # FPR X 축의 Scale을 0.1 단위로 변경, X, Y 축명 설정 등\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel('FPR (1 - Specificity)')\n",
    "    plt.ylabel('TPR (Recall / Sensitivity)')\n",
    "    plt.legend()\n",
    "\n",
    "    # AUC 값 텍스트로 추가\n",
    "    #plt.text(0.6, 0.2, f'AUC = {auc_score:.3f}', fontsize=12, bbox=dict(facecolor='white', alpha=0.6))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "roc_curve_plot(y_test,xgb_model.predict_proba(X_test)[:, 1] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 최적 모델\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# 교차 검증 수행 (최적화된 모델로)\n",
    "cv_results = cross_validate(best_rf_model, X_train, y_train, cv=kf, scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
    "\n",
    "# 각 지표의 평균 결과 출력\n",
    "print(\"\\n교차 검증 결과:\")\n",
    "print(\"정확도 평균:\", np.mean(cv_results['test_accuracy']))\n",
    "print(\"정밀도 평균:\", np.mean(cv_results['test_precision']))\n",
    "print(\"재현율 평균:\", np.mean(cv_results['test_recall']))\n",
    "print(\"F1 점수 평균:\", np.mean(cv_results['test_f1']))\n",
    "\n",
    "# train 데이터 예측 수행\n",
    "print(\"\\ntrain 데이터 예측\")\n",
    "y_train_pred = best_rf_model.predict(X_train)\n",
    "evaluate(y_train,y_train_pred)\n",
    "\n",
    "# test 데이터 예측 수행\n",
    "print(\"\\ntest 데이터 예측\")\n",
    "y_test_pred = best_rf_model.predict(X_test)\n",
    "evaluate(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코비드 예측\n",
    "y_pred=best_rf_model.predict(covid_df)\n",
    "evaluate(covid_y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve_plot(y_test,best_rf_model.predict_proba(X_test)[:, 1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 특성중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "plot_importance(xgb_model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 중요도 추출\n",
    "feature_importances = best_rf_model.feature_importances_\n",
    "\n",
    "# 중요도와 특성 이름을 함께 정리\n",
    "feature_names = X_train.columns\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# 중요도가 높은 순으로 정렬\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 결과 출력\n",
    "print(feature_importance_df)\n",
    "\n",
    "# 특성 중요도를 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
    "plt.title(\"Feature Importance\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
